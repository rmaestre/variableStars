---
output: github_document
---

[![Build Status](https://travis-ci.org/rmaestre/variableStars.svg?branch=master)](https://travis-ci.org/rmaestre/variableStars)


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(variableStars)
library(ggplot2)
library(RColorBrewer)
```



```{r data, echo=F, warning=FALSE}
if (T) {
  dt.star <- data.frame(read.table("data/table1.dat", sep = "\t"))
  colnames(dt.star) <-
    c(
      "Seq",
      "frequency",
      "amplitude",
      "Phase",
      "Sig",
      "S/N",
      "rms",
      "e_Freq",
      "e_Amp",
      "e_Phase"
    )
} else {
  dt.star <- data.frame(read.table("data/freqs.dat", sep = " "))
  colnames(dt.star) <-
    c(
      "Id",
      "frequency",
      "Freq2",
      "amplitude",
      "Phase",
      "Sig",
      "S/N",
      "rms",
      "e_Freq1",
      "e_Amp",
      "e_Phase"
    )
}
```


Please, [read the package introduction](https://github.com/rmaestre/variableStars/blob/master/README.md) for initial details about the software, algorithms, workflow and data used.

Neural Network approach for detecting Dnu and dr
=================================================================

[Depthwise separable convolutions](https://arxiv.org/pdf/1610.02357.pdf) for machine learning consists in *spatial convolution performed independently over each channel of an input, followed by a pointwise convolution, projecting the channels output by the depthwise convolution onto a new channel space. *

The next figure represents an overview of the main Neural Network architecture used to identify Dnu and dr from a given power espectrum of a variable star:

<img src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/nn-approach.png" data-canonical-src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/nn-approach.png" width="500" />


An example of NN output is the following one, in which:

* **Red** = Information related to Dnu
    * Vertical red line = Real value of Dnu [unseen for the NN]
    * Red points = Probabilities over Dnu values infered by the NN
  
* **Black** = Information related to dr
    * Vertical black line = Real value of dr [unseen for the NN]
    * Black points = Probabilities dr infered by the NN
    
(Because each channel is scaled between [0,1], these values and the probabilities can be plotted together)

<img src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/NNoutputexample.png" data-canonical-src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/NNoutputexample.png" width="400" />




Methodology
===============


Input data
-----------

Each input channel channel is processed with the *variableStars* package. The data from the variable star is processed by the main method:

```{r, echo=T}
result <- process(
  dt.star$frequency,
  dt.star$amplitude,
  filter = "uniform",
  gRegimen = 0,
  minDnu = 15,
  maxDnu = 95,
  dnuValue = -1,
  dnuGuessError = 10,
  dnuEstimation = TRUE,
  numFrequencies = 30,
  debug = F
)
```

and each channel is extracted as:

* **Fourier transform**

```{r, echo=T}
dt <- prepare_periodicities_dataset(result$fresAmps)
dt <- dt[dt$label == "30  freqs", ]
plot_periodicities_ggplot(dt)
```

* **Histogram of differences**

```{r, echo=T}
dt <- data.frame(result$diffHistogram$histogram)
plot_histogram_ggplot(dt)
```

* **Autocorrelation** 

```{r, echo=T}
dt <- data.frame(result$crossCorrelation)
plot_crosscorrelation_ggplot(dt)
```

Note: The informaction of each channel is scaled between [0,1].

Neural Network targets
-----------

The input for the Nural Network, is bucketized with a given resolution; transforming the frecuency range into classes:

```{r, echo=T}
input_resolution <- 0.5
# Input dimension
cuts_breaks <- c(seq(0, 101, input_resolution))
cuts_breaks
```

The target output, is bucketized, transforming the frecuency range into classes:

```{r, echo=T}
output_resolution <- 1.0
# Output dimension
output_classes <- seq(from = 0,
                      to = 14 / 0.0864,
                      by = output_resolution)
output_classes
```

Note: Input and output dimension are fixed.


Experiment I
===============

A simple synthetic data without noise added. 28 frequencies are generated with four clear patters.

```{r, echo=F}
set.seed(123)
dt <- generate_data_modes(
        deltaNu = 10,
        deltaR = 7,
        nuRange = c(2.5, 10),
        numPoints = 7
      )
dt$data$amplitude <- 1.0
ggplot(aes(frequency, amplitude, shape=mode, colour=mode), data=dt$data) +
  geom_point(size=2) +
  theme_bw() +
  ggtitle(bquote(Delta*nu~"="~.(dt$dnu) ~ delta*r~"="~.(dt$dr)))
```    
      
The variableStars package process all frequencies and produce the input data for each channel in the NN.

```{r, echo=T}
# Process the data
result <- process(
  dt$data$frequency,
  dt$data$amplitude,
  filter = "uniform",
  gRegimen = 0,
  minDnu = 15,
  maxDnu = 95,
  dnuValue = -1,
  dnuGuessError = 10,
  dnuEstimation = TRUE,
  numFrequencies = nrow(dt$data)+1,
  debug = F
)
plot_periodicities_ggplot(prepare_periodicities_dataset(result$fresAmps))
plot_histogram_ggplot(data.frame(result$diffHistogram$histogram))
plot_crosscorrelation_ggplot(data.frame(result$crossCorrelation))
```


Experiment II
===============

A simple synthetic data noise added. 28 frequencies are generated with four clear patters, plus 15 random frequencies (**53% of random frequencies**). 

```{r, echo=F}
set.seed(123)
dt <- generate_data_modes(
        deltaNu = 10,
        deltaR = 7,
        nuRange = c(2.5, 10),
        numPoints = 7
      )
dt$data <-
        rbind(dt$data,
              data.frame(
                "frequency" = runif(15, min(dt$data$frequency), max(dt$data$frequency)),
                "mode" = "random",
                "amplitude" = 1.0
              ))
      dt$data$amplitude <- 1.0
ggplot(aes(frequency, amplitude, shape=mode, colour=mode), data=dt$data) +
  geom_point(size=2) +
  theme_bw() +
  ggtitle(bquote(Delta*nu~"="~.(dt$dnu) ~ delta*r~"="~.(dt$dr)))
```

The variableStars package process all frequencies and produce the input data for each channel in the NN.

```{r, echo=T}
# Process the data
resultNoisy <- process(
  dt$data$frequency,
  dt$data$amplitude,
  filter = "uniform",
  gRegimen = 0,
  minDnu = 15,
  maxDnu = 95,
  dnuValue = -1,
  dnuGuessError = 10,
  dnuEstimation = TRUE,
  numFrequencies = nrow(dt$data) + 1,
  debug = F
)
plot_periodicities_ggplot(prepare_periodicities_dataset(resultNoisy$fresAmps))
plot_histogram_ggplot(data.frame(resultNoisy$diffHistogram$histogram))
plot_crosscorrelation_ggplot(data.frame(resultNoisy$crossCorrelation))
```    



Results
===================


Confusion matrix
----------------

(Right image=Dnu, Left image=Dr)


**Experiment I**

<img src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-clear-dnu.png" data-canonical-src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-clear-dnu.png" width="400" />
 |  <img src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-clear-dr.png" data-canonical-src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-clear-dr.png" width="400" />


**Experiment II**


<img src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-noisy-dnu.png" data-canonical-src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-noisy-dnu.png" width="400" />
  |  <img src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-noisy-dr.png" data-canonical-src="https://raw.githubusercontent.com/rmaestre/variableStars/master/docs/figures/cm-noisy-dr.png" width="400" />




Validation accuracy/recall
----------------

In our approach, we use **recall @N**. This metric means that, the correct category (Dnu or dr bucket) is found in the first **N** sorted probabilities that the model gives.

```{r, echo=F}
dt <- data.frame("loss"=   c(1.63,1.801,1.814,1.896),
             "recall_at_1"= c(0.408,0.482,0.470,0.467),
             "recall_at_2"= c(0.639,0.672,0.653,0.658),
             "recall_at_4"= c(0.853,0.812,0.816,0.802))
rownames(dt) <- c("Experiment I - Dnu", "Experiment I - Dr", 
                  "Experiment II - Dnu", "Experiment II - Dr")

knitr::kable(dt)
```


Limitations
---------------

* NNs are really sensible to the data input that has been trained. Despite the fact that NN can generalized very well, a robust corresponding between synthetic data generation (theoretical models) and the process itself must be ensured.

* A rigorous NN architecture search must me done. The number of layers and its hyperparameters, dramatically impacts in the NN performance. A grid-search on GPUs has been used as first approach. Next output represents several NN architectures search.

```
loss	 recall_at_1	 recall_at_2	 recall_at_4	architecture
2.8767	0.2015	0.3458	0.5361	[ 6|2|6|3|0.2 ] [ 3|4|9|3|x ] [ 4|8|9|x|0.2 ]
2.0808	0.479	0.6933	0.8404	[ 10|9|7|2|0.4 ] [  ] [  ]
2.1148	0.3962	0.6001	0.7832	[ 6|9|2|3|0.5 ] [ 8|2|5|1|0.3 ] [ 10|4|7|1|0.4 ]
2.4934	0.4486	0.6601	0.8184	[ 9|9|2|1|0.1 ] [ 6|7|3|x|x ] [ 2|2|5|x|0.1 ]
1.7715	0.4446	0.6617	0.8328	[ 8|5|2|2|0.2 ] [ 2|10|5|2|0.2 ] [ 7|5|10|1|0.2 ]
3.3669	0.4018	0.6001	0.7453	[ 2|6|5|1|0.2 ] [ 4|10|2|x|0.2 ] [ 4|10|4|x|x ]
2.303	0.3558	0.5597	0.7461	[ 2|7|7|3|0.4 ] [ 5|2|4|x|0.5 ] [ 6|3|5|x|x ]
2.2361	0.4402	0.6569	0.8184	[ 8|3|3|1|0.3 ] [  ] [  ]
1.6902	0.4946	0.6981	0.8588	[ 8|7|10|3|0.3 ] [ 8|9|8|x|0.4 ] [  ]
2.2283	0.4742	0.6817	0.8316	[ 6|8|7|2|0.3 ] [  ] [  ]
2.1583	0.461	0.6529	0.8068	[ 10|4|9|3|0.1 ] [  ] [  ]
1.9071	0.4462	0.6517	0.8132	[ 5|3|10|3|0.4 ] [  ] [  ]
1.902	0.4482	0.6497	0.81	[ 9|10|6|2|0.3 ] [ 8|9|5|x|0.4 ] [ 2|5|4|2|x ]
1.8427	0.4798	0.6781	0.8356	[ 8|9|6|3|0.4 ] [  ] [  ]
1.9565	0.4234	0.6293	0.8128	[ 5|3|6|3|0.4 ] [  ] [ 9|5|5|x|0.1 ]
1.7707	0.4746	0.6805	0.8352	[ 8|6|4|3|0.5 ] [  ] [ 8|3|4|2|x ]
2.5479	0.4678	0.6577	0.806	[ 2|9|4|2|0.2 ] [  ] [  ]
2.0175	0.429	0.6141	0.7652	[ 6|7|10|3|0.2 ] [ 4|5|9|3|x ] [  ]
1.942	0.4758	0.6801	0.8424	[ 5|4|10|2|0.3 ] [  ] [ 6|4|8|3|x ]
1.8003	0.4814	0.6745	0.828	[ 5|5|7|2|0.2 ] [ 3|8|10|1|0.2 ] [ 3|4|5|x|x ]
2.0301	0.4766	0.6905	0.8428	[ 8|8|4|2|0.4 ] [  ] [  ]
1.854	0.4682	0.6753	0.83	[ 7|2|6|3|0.2 ] [ 2|5|6|x|x ] [  ]
2.054	0.4074	0.6041	0.788	[ 2|2|3|3|0.3 ] [ 9|10|7|x|x ] [  ]
2.4722	0.4434	0.6397	0.8088	[ 9|8|8|1|0.4 ] [ 9|3|7|x|x ] [  ]
1.8565	0.4862	0.6933	0.8472	[ 7|4|5|2|0.3 ] [ 10|3|8|x|x ] [  ]
```
